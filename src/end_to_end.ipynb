{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce85de1-7577-4cc6-bab3-043b36836772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from utils.models import find_best_model\n",
    "from utils.search_model import train_models\n",
    "from utils.get_parameters import max_score_for_each, get_combinations\n",
    "from utils.visual import plot_results\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f61711-0826-4c53-9d41-761b031cda07",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "The first step of model training is to train combinations of algorithm, imputation and balancing approaches\\\n",
    "The algorithms are:\n",
    "\n",
    "    - KNN\n",
    "    - Decision Tree\n",
    "    - Logistic regression\n",
    "    - SVM\n",
    "    - Naive Bayes\n",
    "    - RandomForestClassifier\n",
    "    - GradientBoostingClassifier\n",
    "    - BaggingClassifier\n",
    "    - XGBClassifier\n",
    "\n",
    "The balancing algorithms are:\n",
    "\n",
    "    - SMOTE (oversampling)\n",
    "    - MWMOTE (oversampling)\n",
    "    - ADASYN (oversampling)\n",
    "    - AllKNN (undersampling)\n",
    "    - None (using original data)\n",
    "\n",
    "The imputation techqniues are:\n",
    "\n",
    "    - Simple Imputer with mode: for categorical features\n",
    "    - Simple Imputer with mean: for numerical features\n",
    "    - KNN Imputer with mean: for numerical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc2df8-2541-46f5-a18f-e7dd5753b720",
   "metadata": {},
   "source": [
    "## Project structure\n",
    "\n",
    "- [GitHub](https://github.com/albermakaryan/Machine_learning)\n",
    "\n",
    "- **[data/](data/)**\n",
    "   - **[initial_data/](data/initial_data/)**:  Full data set for modeling\n",
    "   - **[model_data/](data/model_data/)**    :  Period 3 data set\n",
    "- **[src/](src/)**\n",
    "   - **[models/](src/models/)**   :  The best models for each algorithm in .pkl format\n",
    "   - **[results/](src/results/)** :  Performance results for each algorithm and total\n",
    "   - **[utils/](src/utisl/)**     :  Utility functions package\n",
    "      - **[__init__.py](src/utils/__init__.py)**:  Python package initialization\n",
    "      - **[data_preparation.py](src/utils/data_preparation.py)**:  Utility function for data preparation\n",
    "      - **[functions.py](src/utils/functions.py)**:  Utility function for best results combination\n",
    "      - **[get_parameters.py](src/utils/__init__.py)**:  Utility functions for parameters' combination collection \n",
    "      - **[metrics.py](src/utils/metrics.py)**:  Utility function to evaluate model performance\n",
    "      - **[search_model.py](src/utils/search_model.py)**:  Utility function to train default models with several combinations\n",
    "      - **[visual.py](src/utils/visual.py)**:  Utility functions to plot models' performance results\n",
    "      - **[models.py](src/utils/models.py)**:  Utility functions to train 'the best' model for each algorithm\n",
    "   - **[main.py](src/main.py)**:  The main file in a project\n",
    "   - **[eda-1.ipynb](src/eda-1.ipynb)**:  Jupyter Notebook for EDA\n",
    "   - **[end_to_end.ipynb](src/end_to_end.ipynb)**:  Jupyter Notebook for end-to-end workflow presentation\n",
    "   - **[visualizations.ipynb](src/visualizations.ipynb)**:   Jupyter Notebook for visualizations\n",
    "\n",
    "- **[requirements.txt](/requirements.txt)**: The inclusion of a requirements.txt file makes it easier to recreate the project's environment and install the necessary dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedb77f-92bf-47a8-8d78-fa484b0e91a3",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61842cef-d55b-4ff1-8751-a38d5d25f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/initial_data/frmgham2_project_data_full.csv\")\n",
    "print(f\"Shape: {df.shape}\\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea63281-4e49-407b-b9ad-dc44b4b3575a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "performances_df = train_models(df=df,target_var='CVD',\n",
    "                                path_to_save='../src/results/general/full_data_performances_9_models_5_balancers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493a9a8-70f5-4cda-adf3-4847b3b602b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675c83b-9c2b-4408-973c-38a1c88df972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best results\n",
    "\n",
    "test_scores = max_score_for_each(performances_df,set_= 'Test')\n",
    "train_scores = max_score_for_each(performances_df,set_='Train')\n",
    "differences_df = train_scores.rename(columns={'Score':'TrainScore'}).drop(['Metric','Set','Imputer','Imbalance'],axis=1)\\\n",
    "            .merge(test_scores.rename(columns={\"Score\":\"TestScore\"}).drop(['Metric','Set','Imputer','Imbalance'],axis=1),\\\n",
    "                    on=['Algorithm','MainMetric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0476e-abfe-464b-8148-5cfa97d8ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4fa7d-9ce5-4177-8290-213d02e46893",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = performances_df[['Algorithm','Imputer','Imbalance']].drop_duplicates().shape[0]/9\n",
    "print(f\"Number of models for each algorithm: {int(counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d68f11-97dc-4185-b42b-2b34aadbc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model training combinations for training\n",
    "# this is the combination of model, imputation and balancing techniques\n",
    "\n",
    "combinations = get_combinations(df=performances_df,by_features=['Algorithm','Metric'],by_metric='AUC',by_set='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04b0a3-6e42-44d4-8a0d-4cae2198feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of models: \",len(combinations))\n",
    "combinations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80f563-dfe9-48d9-8a39-4758e34889ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/initial_data/frmgham2_project_data_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984d928-6b67-4314-8d85-3e2a6972b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train best models \n",
    "for combination in combinations:\n",
    "    algorithm, imputer,balanc = combination\n",
    "    # print(combination)\n",
    "    # quit()\n",
    "    print(algorithm.__name__,balanc.__name__,imputer)\n",
    "    best_model,best_params,output = find_best_model(algorithm=algorithm,\n",
    "                                                    balancer=balanc,\n",
    "                                                    imputer=imputer,\n",
    "                                                    df=df,\n",
    "                                                    ovewrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6fb3a-1d60-4c62-a42c-b35ecf1e3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_perfomance = pd.read_csv(\"../results/general/best_results_all_models.csv\")\n",
    "total_perfomance_approaches = total_perfomance.drop(['Set','Metric','Score'],axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc727e-1de7-4ca7-ba2f-af9e0d706ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which works better \n",
    "total_perfomance_approaches.sort_values(\"Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f3aea-e8c8-45e5-9c1e-7a9ed32bb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean performance\n",
    "test_performances = total_perfomance[total_perfomance['Set'] == 'Test']\n",
    "# train_erformances = total_perfomance[total_perfomance['Set'] == 'Train']\n",
    "mean_performance = test_performances.groupby(\"Algorithm\",as_index=False)['Score'].mean()\n",
    "mean_performance['Score'] = mean_performance['Score'].round(2)\n",
    "mean_performance.sort_values(\"Score\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d684a-6c65-4fff-b2c2-669a108ffcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "\n",
    "ax.barh(mean_performance['Algorithm'],mean_performance['Score'],color='orange')\n",
    "for j, value in enumerate(mean_performance.Score):  # Changed the variable name to j\n",
    "    ax.annotate(str(value), xy=(value,j), ha='right', va='center')\n",
    "\n",
    "ax.set_xlabel(\"Score\")\n",
    "plt.title(\"Average test performances of algorithms\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d98426-8233-41a9-9a88-3f916358a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algs = [alg.split(\"_\")[0] for alg in os.listdir(\"../models/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb45ad7-ef78-4122-b303-2dbe22906372",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'XGBClassifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b5496-627c-4fcb-b27c-37312b179cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = plot_results(performances_df,algorithm,df,set_='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa506d-1461-4e7c-9165-9dbcbe16d614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course_kernel",
   "language": "python",
   "name": "ml_course_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
